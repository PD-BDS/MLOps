{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, mutual_info_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data From DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"penguins.db\")\n",
    "query = \"\"\"\n",
    "SELECT p.species, p.bill_length_mm, p.bill_depth_mm, p.flipper_length_mm, p.body_mass_g, p.sex, i.name AS island\n",
    "FROM penguins p\n",
    "JOIN islands i ON p.island_id = i.island_id\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding For Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "categorical_cols = ['sex', 'island']\n",
    "encoded_features = encoder.fit_transform(df[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "df = df.drop(columns=categorical_cols).join(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0    Adelie            39.1           18.7              181.0       3750.0   \n",
       "1    Adelie            39.5           17.4              186.0       3800.0   \n",
       "2    Adelie            40.3           18.0              195.0       3250.0   \n",
       "3    Adelie            36.7           19.3              193.0       3450.0   \n",
       "4    Adelie            39.3           20.6              190.0       3650.0   \n",
       "..      ...             ...            ...                ...          ...   \n",
       "328  Gentoo            47.2           13.7              214.0       4925.0   \n",
       "329  Gentoo            46.8           14.3              215.0       4850.0   \n",
       "330  Gentoo            50.4           15.7              222.0       5750.0   \n",
       "331  Gentoo            45.2           14.8              212.0       5200.0   \n",
       "332  Gentoo            49.9           16.1              213.0       5400.0   \n",
       "\n",
       "     sex_Female  sex_Male  island_Biscoe  island_Dream  island_Torgersen  \n",
       "0           0.0       1.0            0.0           0.0               1.0  \n",
       "1           1.0       0.0            0.0           0.0               1.0  \n",
       "2           1.0       0.0            0.0           0.0               1.0  \n",
       "3           1.0       0.0            0.0           0.0               1.0  \n",
       "4           0.0       1.0            0.0           0.0               1.0  \n",
       "..          ...       ...            ...           ...               ...  \n",
       "328         1.0       0.0            1.0           0.0               0.0  \n",
       "329         1.0       0.0            1.0           0.0               0.0  \n",
       "330         0.0       1.0            1.0           0.0               0.0  \n",
       "331         1.0       0.0            1.0           0.0               0.0  \n",
       "332         0.0       1.0            1.0           0.0               0.0  \n",
       "\n",
       "[333 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test Split and Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features and target\n",
    "X = df.drop(columns=['species'])\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on X_train and transform X_train\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores (Filter Method):\n",
      "flipper_length_mm    0.592096\n",
      "bill_depth_mm        0.589186\n",
      "bill_length_mm       0.560094\n",
      "body_mass_g          0.515296\n",
      "island_Biscoe        0.411411\n",
      "island_Dream         0.387965\n",
      "island_Torgersen     0.113053\n",
      "sex_Male             0.012188\n",
      "sex_Female           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter Method (SelectKBest)\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')  \n",
    "selector.fit(X_train_scaled, y_train) \n",
    "\n",
    "# Mutual Information Scores\n",
    "mi_scores = pd.Series(selector.scores_, index=X.columns)\n",
    "\n",
    "mi_scores.sort_values(ascending=False, inplace=True) \n",
    "\n",
    "print(\"Mutual Information Scores (Filter Method):\")\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recursive Feature Elimination (RFE) Feature Importance Scores:\n",
      "bill_length_mm       0.392176\n",
      "flipper_length_mm    0.295160\n",
      "bill_depth_mm        0.168422\n",
      "island_Dream         0.144242\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Wrapper Method (Recursive Feature Elimination)\n",
    "rfe_model = RandomForestClassifier(random_state=42)\n",
    "rfe = RFE(estimator=rfe_model, n_features_to_select=None) \n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extracting feature importance scores \n",
    "rfe_features = X.columns[rfe.support_] \n",
    "feature_importance = pd.Series(rfe.estimator_.feature_importances_, index=rfe_features)\n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\nRecursive Feature Elimination (RFE) Feature Importance Scores:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importance (Embedded Method):\n",
      "bill_length_mm       0.339403\n",
      "flipper_length_mm    0.271055\n",
      "bill_depth_mm        0.144621\n",
      "island_Dream         0.074662\n",
      "body_mass_g          0.072502\n",
      "island_Biscoe        0.070673\n",
      "island_Torgersen     0.020646\n",
      "sex_Male             0.003245\n",
      "sex_Female           0.003194\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3. Embedded Method (Feature Importance from RandomForest)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X.columns) \n",
    "feature_importance.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "print(\"Random Forest Feature Importance (Embedded Method):\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance Scores:\n",
      "flipper_length_mm    0.262687\n",
      "bill_length_mm       0.176119\n",
      "island_Dream         0.149254\n",
      "bill_depth_mm        0.023881\n",
      "island_Biscoe        0.005970\n",
      "island_Torgersen     0.002985\n",
      "body_mass_g          0.002985\n",
      "sex_Female           0.000000\n",
      "sex_Male             0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. Permutation Importance \n",
    "perm_importance = permutation_importance(model, X_test_scaled, y_test, scoring=\"accuracy\") \n",
    "\n",
    "perm_scores = pd.Series(perm_importance.importances_mean, index=X.columns)\n",
    "perm_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "print(\"Permutation Importance Scores:\")\n",
    "print(perm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection Results\n",
      "          Feature Mutual Info RFE Random Forest Permutation  Feature Importance\n",
      "   bill_length_mm           ✅   ✅             ✅           ✅         Important ✅\n",
      "    bill_depth_mm           ✅   ✅             ✅           ❌         Important ✅\n",
      "flipper_length_mm           ✅   ✅             ✅           ✅         Important ✅\n",
      "      body_mass_g           ❌   ❌             ❌           ❌     Not Important ❌\n",
      "       sex_Female           ❌   ❌             ❌           ❌     Not Important ❌\n",
      "         sex_Male           ❌   ❌             ❌           ❌     Not Important ❌\n",
      "    island_Biscoe           ❌   ❌             ❌           ❌     Not Important ❌\n",
      "     island_Dream           ❌   ✅             ❌           ✅     Not Important ❌\n",
      " island_Torgersen           ❌   ❌             ❌           ❌     Not Important ❌\n"
     ]
    }
   ],
   "source": [
    "# Creating Summary Table for Feature Selection\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# function fro marking features for selection decision \n",
    "def mark_features(feature, methods):\n",
    "    return \"✅\" if feature in methods else \"❌\"\n",
    "\n",
    "# Table Creation\n",
    "feature_table = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Mutual Info\": [mark_features(f, mi_scores.head(3).index.tolist()) for f in features],\n",
    "    \"RFE\": [mark_features(f, rfe_features) for f in features],\n",
    "    \"Random Forest\": [mark_features(f, feature_importance.head(3).index.tolist()) for f in features],\n",
    "    \"Permutation\": [mark_features(f, perm_scores.head(3).index.tolist()) for f in features]\n",
    "})\n",
    "\n",
    "feature_table[\" Feature Importance\"] = feature_table[[\"Mutual Info\", \"RFE\", \"Random Forest\", \"Permutation\"]].apply(\n",
    "    lambda row: \"Important ✅\" if list(row).count(\"✅\") >= 3 else \"Not Important ❌\", axis=1\n",
    ")\n",
    "\n",
    "print(\"Feature Selection Results\")\n",
    "print(feature_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Selected Features:\n",
      "['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm']\n"
     ]
    }
   ],
   "source": [
    "# Select features that are marked as \"Important ✅\"\n",
    "final_features = feature_table.loc[feature_table[\" Feature Importance\"] == \"Important ✅\", \"Feature\"].tolist()\n",
    "\n",
    "print(\"Final Selected Features:\")\n",
    "print(final_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 42}\n",
      "Final Model Accuracy: 0.99\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      0.97      0.98        29\n",
      "   Chinstrap       0.93      1.00      0.97        14\n",
      "      Gentoo       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           0.99        67\n",
      "   macro avg       0.98      0.99      0.98        67\n",
      "weighted avg       0.99      0.99      0.99        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "# Using Oversampling (SMOTE) class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Model Initialization\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Using GridSearchCV for finding optimal estimators\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and scaler\n",
    "joblib.dump(grid_search.best_estimator_, \"penguin_classifier.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"Model trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features: [[  1.09915228  92.75303472 -13.07912805]\n",
      " [  0.18559614  82.60356005 -13.15048143]\n",
      " [ -0.72796     87.67829739 -13.00777467]\n",
      " [  2.92626457  97.82777206 -12.93642129]]\n",
      "Prediction for penguin 1: Chinstrap\n",
      "Prediction for penguin 2: Adelie\n",
      "Prediction for penguin 3: Adelie\n",
      "Prediction for penguin 4: Chinstrap\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import load\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the saved model and scaler\n",
    "model = load(\"penguin_classifier.pkl\")\n",
    "scaler = load(\"scaler.pkl\")\n",
    "\n",
    "# Example data for multiple penguins (bill_length, flipper_length, bill_depth)\n",
    "test_data = np.array([\n",
    "    [50.0, 200.0, 18.0],  # Example 1\n",
    "    [45.0, 180.0, 17.0],  # Example 2\n",
    "    [40.0, 190.0, 19.0],  # Example 3\n",
    "    [60.0, 210.0, 20.0],  # Example 4\n",
    "])\n",
    "\n",
    "# Scale the features using the loaded scaler\n",
    "scaled_features = scaler.transform(test_data)\n",
    "\n",
    "# Print the scaled features to see if the transformation is working as expected\n",
    "print(\"Scaled features:\", scaled_features)\n",
    "\n",
    "# Use the model to make predictions for all examples\n",
    "predicted_classes = model.predict(scaled_features)\n",
    "\n",
    "# Print predictions for all examples\n",
    "for i, predicted_class in enumerate(predicted_classes):\n",
    "    print(f\"Prediction for penguin {i+1}: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
